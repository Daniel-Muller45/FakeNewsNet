{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time-Based Analysis of Fake News Patterns\n",
    "\n",
    "This notebook analyzes how fake news characteristics evolve over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Set style for plots\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "bf_fake_df = pd.read_csv(\"../data/BuzzFeed_fake_news_content.csv\")\n",
    "bf_real_df = pd.read_csv(\"../data/BuzzFeed_real_news_content.csv\")\n",
    "pf_fake_df = pd.read_csv(\"../data/PolitiFact_fake_news_content.csv\")\n",
    "pf_real_df = pd.read_csv(\"../data/PolitiFact_real_news_content.csv\")\n",
    "\n",
    "# Add labels\n",
    "bf_fake_df['label'] = 1  # 1 for fake news\n",
    "bf_real_df['label'] = 0  # 0 for real news\n",
    "pf_fake_df['label'] = 1\n",
    "pf_real_df['label'] = 0\n",
    "\n",
    "# Add dataset identifier\n",
    "bf_fake_df['dataset'] = 'BuzzFeed'\n",
    "bf_real_df['dataset'] = 'BuzzFeed'\n",
    "pf_fake_df['dataset'] = 'PolitiFact'\n",
    "pf_real_df['dataset'] = 'PolitiFact'\n",
    "\n",
    "# Combine all data for temporal analysis\n",
    "all_data = pd.concat([bf_fake_df, bf_real_df, pf_fake_df, pf_real_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract date from various formats\n",
    "def extract_date(date_str):\n",
    "    if pd.isna(date_str):\n",
    "        return None\n",
    "    \n",
    "    # Check if the date is in dictionary format with $date key\n",
    "    if isinstance(date_str, str) and date_str.startswith('{'):\n",
    "        try:\n",
    "            date_dict = json.loads(date_str.replace(\"'\", '\"'))\n",
    "            if '$date' in date_dict:\n",
    "                # Convert Unix timestamp (milliseconds) to datetime\n",
    "                timestamp = int(date_dict['$date']) / 1000  # Convert to seconds\n",
    "                return datetime.fromtimestamp(timestamp)\n",
    "        except (json.JSONDecodeError, ValueError):\n",
    "            pass\n",
    "    \n",
    "    # Try common date formats\n",
    "    date_formats = [\n",
    "        '%Y-%m-%d',\n",
    "        '%Y/%m/%d',\n",
    "        '%d-%m-%Y',\n",
    "        '%d/%m/%Y',\n",
    "        '%B %d, %Y',\n",
    "        '%b %d, %Y'\n",
    "    ]\n",
    "    \n",
    "    for fmt in date_formats:\n",
    "        try:\n",
    "            return datetime.strptime(date_str, fmt)\n",
    "        except (ValueError, TypeError):\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Apply the function to standardize dates\n",
    "all_data['parsed_date'] = all_data['publish_date'].apply(extract_date)\n",
    "\n",
    "# Add year, month, day columns for easier analysis\n",
    "all_data['year'] = all_data['parsed_date'].apply(lambda x: x.year if x is not None else None)\n",
    "all_data['month'] = all_data['parsed_date'].apply(lambda x: x.month if x is not None else None)\n",
    "all_data['day'] = all_data['parsed_date'].apply(lambda x: x.day if x is not None else None)\n",
    "\n",
    "# Drop rows with no date information for time analysis\n",
    "dated_data = all_data.dropna(subset=['parsed_date']).copy()\n",
    "\n",
    "# Add day of week\n",
    "dated_data['day_of_week'] = dated_data['parsed_date'].apply(lambda x: x.weekday())\n",
    "\n",
    "# Show how many articles have valid dates\n",
    "print(f\"Total articles: {len(all_data)}\")\n",
    "print(f\"Articles with valid dates: {len(dated_data)} ({len(dated_data)/len(all_data)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of articles over time by real/fake label\n",
    "plt.figure(figsize=(14, 6))\n",
    "ax = sns.histplot(data=dated_data, x='parsed_date', hue='label', bins=20, element='step')\n",
    "plt.title('Distribution of Articles Over Time by Label')\n",
    "plt.xlabel('Publication Date')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(['Real News', 'Fake News'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles by month of year\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=dated_data, x='month', hue='label')\n",
    "plt.title('Distribution of Articles by Month')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(range(12), ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "plt.legend(['Real News', 'Fake News'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Articles by day of week\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.countplot(data=dated_data, x='day_of_week', hue='label')\n",
    "plt.title('Distribution of Articles by Day of Week')\n",
    "plt.xlabel('Day of Week')\n",
    "plt.ylabel('Number of Articles')\n",
    "plt.xticks(range(7), ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'])\n",
    "plt.legend(['Real News', 'Fake News'])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined text field\n",
    "dated_data['combined_text'] = dated_data['title'].fillna('') + ' ' + dated_data['text'].fillna('')\n",
    "\n",
    "# Group data by year and label\n",
    "years = sorted(dated_data['year'].dropna().unique())\n",
    "print(f\"Years in dataset: {years}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze language patterns for a given year\n",
    "def analyze_year_language(year):\n",
    "    # Select data for this year\n",
    "    year_data = dated_data[dated_data['year'] == year]\n",
    "    fake_texts = year_data[year_data['label'] == 1]['combined_text'].tolist()\n",
    "    real_texts = year_data[year_data['label'] == 0]['combined_text'].tolist()\n",
    "    \n",
    "    # If no data for this label in this year, return empty lists\n",
    "    if not fake_texts or not real_texts:\n",
    "        return ([], [])\n",
    "    \n",
    "    # Calculate word frequencies\n",
    "    vectorizer = TfidfVectorizer(max_features=20, stop_words='english')\n",
    "    \n",
    "    # Fake news top words\n",
    "    try:\n",
    "        tfidf_fake = vectorizer.fit_transform(fake_texts)\n",
    "        fake_words = vectorizer.get_feature_names_out()\n",
    "        fake_scores = np.mean(tfidf_fake.toarray(), axis=0)\n",
    "        fake_top_words = [(fake_words[i], fake_scores[i]) for i in fake_scores.argsort()[::-1][:5]]\n",
    "    except ValueError:\n",
    "        fake_top_words = []\n",
    "    \n",
    "    # Real news top words\n",
    "    try:\n",
    "        tfidf_real = vectorizer.fit_transform(real_texts)\n",
    "        real_words = vectorizer.get_feature_names_out()\n",
    "        real_scores = np.mean(tfidf_real.toarray(), axis=0)\n",
    "        real_top_words = [(real_words[i], real_scores[i]) for i in real_scores.argsort()[::-1][:5]]\n",
    "    except ValueError:\n",
    "        real_top_words = []\n",
    "    \n",
    "    return (fake_top_words, real_top_words)\n",
    "\n",
    "# Calculate language patterns by year\n",
    "year_language = {}\n",
    "for year in years:\n",
    "    year_language[year] = analyze_year_language(year)\n",
    "\n",
    "# Display top words by year\n",
    "for year in years:\n",
    "    fake_top, real_top = year_language[year]\n",
    "    \n",
    "    if fake_top and real_top:\n",
    "        print(f\"\\nYear: {year}\")\n",
    "        print(\"Top words in FAKE news:\")\n",
    "        for word, score in fake_top:\n",
    "            print(f\"  {word}: {score:.4f}\")\n",
    "            \n",
    "        print(\"\\nTop words in REAL news:\")\n",
    "        for word, score in real_top:\n",
    "            print(f\"  {word}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for time-based model evaluation\n",
    "def train_test_by_time(train_years, test_years):\n",
    "    # Filter BuzzFeed data by training years\n",
    "    bf_train = pd.concat([bf_fake_df, bf_real_df], ignore_index=True)\n",
    "    bf_train['parsed_date'] = bf_train['publish_date'].apply(extract_date)\n",
    "    bf_train['year'] = bf_train['parsed_date'].apply(lambda x: x.year if x is not None else None)\n",
    "    bf_train = bf_train.dropna(subset=['year'])\n",
    "    bf_train = bf_train[bf_train['year'].isin(train_years)]\n",
    "    \n",
    "    # Filter PolitiFact data by test years\n",
    "    pf_test = pd.concat([pf_fake_df, pf_real_df], ignore_index=True)\n",
    "    pf_test['parsed_date'] = pf_test['publish_date'].apply(extract_date)\n",
    "    pf_test['year'] = pf_test['parsed_date'].apply(lambda x: x.year if x is not None else None)\n",
    "    pf_test = pf_test.dropna(subset=['year'])\n",
    "    pf_test = pf_test[pf_test['year'].isin(test_years)]\n",
    "    \n",
    "    if len(bf_train) == 0 or len(pf_test) == 0:\n",
    "        return None, None, None, None\n",
    "    \n",
    "    # Prepare text data\n",
    "    bf_train['combined_text'] = bf_train['title'].fillna('') + ' ' + bf_train['text'].fillna('')\n",
    "    pf_test['combined_text'] = pf_test['title'].fillna('') + ' ' + pf_test['text'].fillna('')\n",
    "    \n",
    "    # Create feature vectors\n",
    "    X_train = bf_train['combined_text']\n",
    "    y_train = bf_train['label']\n",
    "    X_test = pf_test['combined_text']\n",
    "    y_test = pf_test['label']\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define time periods for analysis based on actual years in your dataset\n",
    "# You may need to adjust these based on the years present in your data\n",
    "early_years = [min(years), min(years) + 1]\n",
    "later_years = [max(years) - 1, max(years)]\n",
    "\n",
    "time_periods = [\n",
    "    {'name': 'Early', 'train_years': early_years, 'test_years': early_years},\n",
    "    {'name': 'Later', 'train_years': later_years, 'test_years': later_years},\n",
    "    {'name': 'Train-Early-Test-Later', 'train_years': early_years, 'test_years': later_years},\n",
    "    {'name': 'Train-Later-Test-Early', 'train_years': later_years, 'test_years': early_years}\n",
    "]\n",
    "\n",
    "# Evaluate models for each time period\n",
    "results = []\n",
    "\n",
    "for period in time_periods:\n",
    "    X_train, y_train, X_test, y_test = train_test_by_time(period['train_years'], period['test_years'])\n",
    "    \n",
    "    if X_train is None:\n",
    "        print(f\"Skipping period {period['name']} - insufficient data\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\nEvaluating period: {period['name']}\")\n",
    "    print(f\"Training on years {period['train_years']} ({len(X_train)} articles)\")\n",
    "    print(f\"Testing on years {period['test_years']} ({len(X_test)} articles)\")\n",
    "    \n",
    "    # TF-IDF Vectorization\n",
    "    vectorizer = TfidfVectorizer(stop_words='english', max_features=1000)\n",
    "    X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Logistic Regression\n",
    "    lr_model = LogisticRegression(max_iter=1000, C=1.0)\n",
    "    lr_model.fit(X_train_tfidf, y_train)\n",
    "    lr_preds = lr_model.predict(X_test_tfidf)\n",
    "    lr_accuracy = accuracy_score(y_test, lr_preds)\n",
    "    lr_f1 = f1_score(y_test, lr_preds)\n",
    "    \n",
    "    # Random Forest\n",
    "    rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf_model.fit(X_train_tfidf, y_train)\n",
    "    rf_preds = rf_model.predict(X_test_tfidf)\n",
    "    rf_accuracy = accuracy_score(y_test, rf_preds)\n",
    "    rf_f1 = f1_score(y_test, rf_preds)\n",
    "    \n",
    "    print(f\"\\nLogistic Regression - Accuracy: {lr_accuracy:.4f}, F1 Score: {lr_f1:.4f}\")\n",
    "    print(f\"Random Forest - Accuracy: {rf_accuracy:.4f}, F1 Score: {rf_f1:.4f}\")\n",
    "    \n",
    "    results.append({\n",
    "        'period': period['name'],\n",
    "        'lr_accuracy': lr_accuracy,\n",
    "        'lr_f1': lr_f1,\n",
    "        'rf_accuracy': rf_accuracy,\n",
    "        'rf_f1': rf_f1\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to dataframe and visualize\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize accuracy across time periods\n",
    "if 'results_df' in locals() and len(results_df) > 0:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    bar_width = 0.35\n",
    "    index = np.arange(len(results_df))\n",
    "\n",
    "    plt.bar(index, results_df['lr_accuracy'], bar_width, label='Logistic Regression')\n",
    "    plt.bar(index + bar_width, results_df['rf_accuracy'], bar_width, label='Random Forest')\n",
    "\n",
    "    plt.xlabel('Time Period')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Model Accuracy Across Different Time Periods')\n",
    "    plt.xticks(index + bar_width / 2, results_df['period'])\n",
    "    plt.legend()\n",
    "    plt.ylim(0.5, 1.0)  # Set y-axis to start from 0.5 for better visualization\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The time-based analysis reveals how fake news patterns evolve and affect model performance over different time periods. Key insights include:\n",
    "\n",
    "1. Publication patterns show when fake news is most likely to appear\n",
    "2. The language and topics of fake news change over time\n",
    "3. Models perform differently when trained and tested on different time periods\n",
    "4. This suggests fake news detection systems need regular updates to remain effective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
